# -*- coding: utf-8 -*-
"""AirDraw

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bac22FZGhTBQxXWpb4jfMYJm0IChWWZb
"""

!unzip raw_data.zip

!pip install numpy pandas scipy scikit-learn matplotlib tensorflow

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from scipy.signal import resample
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense
from tensorflow.keras.utils import to_categorical

DATA_DIR = "/content/raw_data"
TIMESTEPS = 200
NUM_CLASSES = 10
EPOCHS = 25
BATCH_SIZE = 32

X = []
y = []

SENSOR_COLS = ['AX', 'AY', 'AZ', 'GX', 'GY', 'GZ']

# Loop through digit folders
for folder in os.listdir(DATA_DIR):

    folder_path = os.path.join(DATA_DIR, folder)

    # Only process folders that look like digitX
    if not os.path.isdir(folder_path):
        continue
    if not folder.startswith("digit"):
        continue

    # extract label from folder name
    try:
        label = int(folder.replace("digit", ""))
    except:
        print("Skipping folder (bad label):", folder)
        continue

    # Loop through CSV files inside folder
    for file in os.listdir(folder_path):

        if not file.endswith(".csv"):
            continue

        path = os.path.join(folder_path, file)

        try:
            df = pd.read_csv(path)
        except:
            print("Skipping unreadable file:", path)
            continue

        # check required columns
        if not all(col in df.columns for col in SENSOR_COLS):
            print("Skipping (missing columns):", path)
            continue

        df = df[SENSOR_COLS]
        df = df.apply(pd.to_numeric, errors='coerce').dropna()

        if len(df) < 30:
            print("Skipping (too short):", path)
            continue

        # resample to fixed length
        data = resample(df.values, TIMESTEPS)

        X.append(data)
        y.append(label)

print("DONE LOADING DATA")
print("Total samples:", len(X))

X = np.array(X)
y = np.array(y)

print("X shape:", X.shape)   # (samples, 200, 6)
print("y shape:", y.shape)

if X.ndim != 3:
    raise ValueError("❌ X must be 3D (samples, timesteps, features)")

from collections import Counter
print("Class distribution:", Counter(y))

samples, timesteps, features = X.shape

X_flat = X.reshape(samples * timesteps, features)

scaler = StandardScaler()
X_flat = scaler.fit_transform(X_flat)

# remove NaN / Inf if any
X_flat = np.nan_to_num(X_flat)

X = X_flat.reshape(samples, timesteps, features)

print("NaN present:", np.isnan(X).any())
print("Inf present:", np.isinf(X).any())

y_cat = to_categorical(y, NUM_CLASSES)

X_train, X_test, y_train, y_test = train_test_split(
    X, y_cat,
    test_size=0.2,
    random_state=42
)

print("Train:", X_train.shape)
print("Test:", X_test.shape)

model = Sequential([
    Conv1D(32, 5, activation='relu', input_shape=(TIMESTEPS, 6)),
    MaxPooling1D(2),

    Conv1D(64, 5, activation='relu'),
    MaxPooling1D(2),

    LSTM(32),

    Dense(32, activation='relu'),
    Dense(NUM_CLASSES, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

history = model.fit(
    X_train, y_train,
    epochs=EPOCHS,
    batch_size=1,     # IMPORTANT for tiny dataset
    shuffle=True
)

loss, acc = model.evaluate(X_test, y_test)
print(f"✅ Test Accuracy: {acc*100:.2f}%")

y_pred = model.predict(X_test)
y_pred_cls = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

print(classification_report(y_true, y_pred_cls))

cm = confusion_matrix(y_true, y_pred_cls)

plt.figure(figsize=(7,6))
plt.imshow(cm, cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.colorbar()
plt.show()

model.save("airdraw_model.h5")